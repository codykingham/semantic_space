{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Selection Development\n",
    "\n",
    "**TODO 10.03.18**\n",
    "\n",
    "Currently the algorithm excludes phrase atoms that begin with the direct object marker. This is a problem, of course, for Objc function phrases. `is_preposition_subj` should be rewritten to check for valid phrase types. This may be tricky since not all את markers will be functioning as an object marker. So: fixing this requires first an exploration of the subphrase relation codes or phrase atom relations that can occur with את. I'm assuming that the specification relation will communicate an adjectival, rather than grammatical, force.\n",
    "\n",
    "This gets even trickier when nouns in the object phrase are marked by markers other than את. I should see whether this happens, and if it does, can a workaround be built with the relation features.\n",
    "\n",
    "For testing: \n",
    "\n",
    "('Joshua', 24, 18) <br>\n",
    "722643 אֶת־כָּל־הָעַמִּ֗ים וְאֶת־הָאֱמֹרִ֛י <br>\n",
    "sp:  אֶת־כָּל־הָעַמִּ֗ים <br>\n",
    "par:  אֶת־הָאֱמֹרִ֛י <br>\n",
    "עַמִּ֗ים <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, I load the necesssary modules, data, and helper functions.\n",
    "import collections\n",
    "from tf.fabric import Fabric\n",
    "from functions.helpers import show_results, filter_results\n",
    "\n",
    "# load BHSA data into TF\n",
    "TF = Fabric(locations='~/github/etcbc/bhsa/tf', modules='c', silent=True)\n",
    "api = TF.load('''\n",
    "                book chapter verse\n",
    "                function sp pdp mother\n",
    "                rela typ lex\n",
    "              ''', silent=True)\n",
    "api.makeAvailableIn(globals()) # globalize TF methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_preposition_subj(word):\n",
    "    '''\n",
    "    Return boolean on whether a word is a preposition subject,\n",
    "    necessary for cases in which the subject is marked in\n",
    "    a prepositional phrase, such as in passive clauses.\n",
    "    Require a word node.\n",
    "    \n",
    "    *Caution*\n",
    "    Does not capture cases such as Gen 21:5 (ca# 516487)\n",
    "    '''\n",
    "    # get word phrase\n",
    "    w_phrase = L.u(word, otype='phrase')[0]\n",
    "    \n",
    "    # get all phrase atoms in the phrase    \n",
    "    # exclude negations and conjunctions\n",
    "    phrase_atoms = [phrs_at for phrs_at in L.d(w_phrase, otype='phrase_atom')\n",
    "                        if F.typ.v(phrs_at) not in {'NegP','CP'}\n",
    "                   ]\n",
    "    \n",
    "    # check whether the only phrase atom in the phrase is a prep. phrase\n",
    "    if len(phrase_atoms) == 1 and F.typ.v(phrase_atoms[0]) == 'PP':\n",
    "        \n",
    "        # is a prepositional subject\n",
    "        return True\n",
    "\n",
    "    else:\n",
    "        # is not a prep subj\n",
    "        return False\n",
    "\n",
    "def get_KL_head(KL_wordnode, good_pdp, good_sp):\n",
    "    '''\n",
    "    Extract the head noun in a כֹל construct chain.\n",
    "    The function simply returns the first substantive in the chain.\n",
    "    '''\n",
    "    \n",
    "    rectum = E.mother.t(KL_wordnode) # get rectum subphrase\n",
    "    KL_phrase = L.d(L.u(KL_wordnode, 'phrase')[0], 'word') # for phrase boundary\n",
    "    \n",
    "    if not rectum:\n",
    "        return False  # KL not in norm. construct (e.g. w/ verbs)\n",
    "    \n",
    "    # get words and nouns in the rectum subphrase\n",
    "    r_words = L.d(rectum[0], 'word')\n",
    "    r_nouns = [w for w in r_words \n",
    "               if F.sp.v(w) in good_sp\n",
    "               and F.pdp.v(w) in good_pdp\n",
    "               and w in KL_phrase\n",
    "              ]\n",
    "    \n",
    "    if r_nouns:\n",
    "        return r_nouns[0] # return the first noun\n",
    "    else:\n",
    "        return None # no noun found, return nothing\n",
    "    \n",
    "    \n",
    "def get_heads(phrase):\n",
    "    '''\n",
    "    Returns substantive head nouns, if there are any, from a phrase node.\n",
    "    \"substantive\" does not include prounouns.\n",
    "    \n",
    "    Based on a supplied phrase get phrase atom and subphrase features \n",
    "    and compare them against a group of sets.\n",
    "    Define those sets first. Then make the comparison.\n",
    "    \n",
    "    *Caution* \n",
    "    This function works reasonably well,\n",
    "    but there are a number of edge cases that it does not catch.\n",
    "    Fine-tuning this function would make a nice notebook in itself.\n",
    "    See Gen 20:5 for a good edge case example, in which both היא pronouns\n",
    "    are registered as subjects, but only one should be.\n",
    "    '''\n",
    "    \n",
    "    good_sp = {'subs', 'nmpr', 'adjv'}\n",
    "    good_pdp = {'subs', 'nmpr'}\n",
    "\n",
    "    # exclude words in phrase_atoms with these relation features\n",
    "    omit_pa_rela = {'Appo', # apposition\n",
    "                    'Spec'} # specification\n",
    "    \n",
    "    # exclude words in subphrases with these relation features\n",
    "    omit_sp_rela = {'rec', # nomen rectum\n",
    "                    'adj', # adjunct \n",
    "                    'atr', # attributive\n",
    "                    'mod', # modifier\n",
    "                    'dem'} # demontrative\n",
    "        \n",
    "    heads = [] # nouns go here\n",
    "    phrase_words = L.d(phrase, 'word')\n",
    "        \n",
    "    for word in phrase_words:\n",
    "        \n",
    "        # get phrases's phrase atoms, subphrases, and subphrase relations\n",
    "        phrase_atom = L.u(word, 'phrase_atom')[0]\n",
    "        subphrases = L.u(word, 'subphrase') \n",
    "        sp_relas = set(F.rela.v(sp) for sp in subphrases)\n",
    "\n",
    "        # compare word/phrase features\n",
    "        if all([\n",
    "                F.pdp.v(word) in good_sp, # is noun\n",
    "                F.sp.v(word) in good_pdp, # is noun\n",
    "                F.typ.v(phrase_atom) == 'NP' or is_preposition_subj(word), # is noun phrase or prep. subj.\n",
    "                F.rela.v(phrase_atom) not in omit_pa_rela, # is valid hrase_atom rela.\n",
    "                not sp_relas & omit_sp_rela, # is valid subphrase rela.\n",
    "               ]):\n",
    "        \n",
    "            # handle כֹל constructs by retrieving their noun:\n",
    "            if F.lex.v(word) == 'KL/':\n",
    "                KL_head = get_KL_head(word, good_pdp, good_sp) # returns word node or None\n",
    "                if KL_head:\n",
    "                    heads.append(KL_head) # כֹל + noun found\n",
    "                else:\n",
    "                    continue # no noun found, skip it\n",
    "            else:\n",
    "                heads.append(word) # word is a head\n",
    "    \n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "# ct = 0\n",
    "\n",
    "# for phrase in F.function.s('Objc'):\n",
    "    \n",
    "#     heads = get_heads(phrase)\n",
    "    \n",
    "#     if heads and len(heads) < len(L.d(phrase, 'word')):\n",
    "        \n",
    "#         print(T.sectionFromNode(phrase))\n",
    "#         print(T.text(L.d(L.u(phrase, 'clause')[0], 'word')))\n",
    "#         print(phrase)\n",
    "#         print(T.text(L.d(phrase, 'word')))\n",
    "#         heads = [T.text([head]) for head in heads]\n",
    "#         print(' | '.join(heads))\n",
    "#         print()\n",
    "        \n",
    "#         ct += 1\n",
    "        \n",
    "#         if ct == 100:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, word in enumerate(F.lex.s('KL/')):\n",
    "        \n",
    "#     daughter = E.mother.t(word)\n",
    "    \n",
    "#     if F.otype.v(word) == 'lex':\n",
    "#         continue\n",
    "    \n",
    "#     phrase = L.u(word, 'phrase')[0]\n",
    "    \n",
    "#     if F.function.v(phrase) not in {'Subj', 'Objc'}:\n",
    "#         continue\n",
    "    \n",
    "#     heads = get_heads(phrase)\n",
    "#     lemmas = list(F.lex.v(w) for w in L.d(phrase, 'word'))\n",
    "    \n",
    "#     if heads and len(heads) > 1 and lemmas.count('KL/') == 1:\n",
    "                \n",
    "#         print(T.sectionFromNode(word))\n",
    "#         print(T.text(L.d(phrase, 'word')), phrase)\n",
    "#         print(T.text(L.d(daughter[0], 'word')))\n",
    "#         print('|'.join(T.text([n]) for n in heads))\n",
    "#         print()\n",
    "        \n",
    "#     if i > 200:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests = list()\n",
    "\n",
    "# for i, word in enumerate(F.lex.s('KL/')):\n",
    "            \n",
    "#     if F.otype.v(word) == 'lex':\n",
    "#         continue\n",
    "    \n",
    "#     phrase = L.u(word, 'phrase')[0]\n",
    "    \n",
    "#     if F.function.v(phrase) not in {'Subj', 'Objc'}:\n",
    "#         continue\n",
    "    \n",
    "#     subphrases = L.u(word, 'subphrase')\n",
    "    \n",
    "#     for sp in subphrases:\n",
    "        \n",
    "#         daughter = E.mother.t(sp)[0] if E.mother.t(sp) else None\n",
    "        \n",
    "#         if not daughter:\n",
    "#             continue\n",
    "        \n",
    "#         d_words = set(F.lex.v(w) for w in L.d(daughter, 'word'))\n",
    "        \n",
    "#         if F.rela.v(daughter) == 'par' and not d_words & {'KL/'}:\n",
    "            \n",
    "#             heads = get_heads(phrase)\n",
    "            \n",
    "#             print(T.sectionFromNode(word))\n",
    "#             print(phrase, T.text(L.d(phrase, 'word')))\n",
    "#             print('sp: ', T.text(L.d(sp, 'word')))\n",
    "#             print('par: ', T.text(L.d(daughter, 'word')))\n",
    "#             print('|'.join(T.text([n]) for n in heads))\n",
    "#             print()\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
