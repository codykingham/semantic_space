{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Lab\n",
    "\n",
    "Evaluating and constructing TF search templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 4.3.4\n",
      "Api reference : https://dans-labs.github.io/text-fabric/Api/General/\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "118 features found and 0 ignored\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Documentation:** <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa\" title=\"{provenance of this corpus}\">BHSA</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/0_home.html\" title=\"{CORPUS} feature documentation\">Feature docs</a> <a target=\"_blank\" href=\"https://dans-labs.github.io/text-fabric/Api/Bhsa/\" title=\"BHSA API documentation\">BHSA API</a> <a target=\"_blank\" href=\"https://dans-labs.github.io/text-fabric/Api/General/\" title=\"text-fabric-api\">Text-Fabric API 4.3.4</a> <a target=\"_blank\" href=\"https://dans-labs.github.io/text-fabric/Api/General/#search-templates\" title=\"Search Templates Introduction and Reference\">Search Reference</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "This notebook online:\n",
       "<a target=\"_blank\" href=\"http://nbviewer.jupyter.org/github/verb_semantics/project_code/blob/master/datareview/.ipynb\">NBViewer</a>\n",
       "<a target=\"_blank\" href=\"https://github.com/verb_semantics/project_code/blob/master/datareview/.ipynb\">GitHub</a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".verse {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".vl {\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: ltr;\n",
       "}\n",
       ".sentence,.clause,.phrase {\n",
       "    margin-top: -1.2em;\n",
       "    margin-left: 1em;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 0.3em;\n",
       "    border-style: solid;\n",
       "    border-radius: 0.2em;\n",
       "    font-size: small;\n",
       "    display: block;\n",
       "    width: fit-content;\n",
       "    max-width: fit-content;\n",
       "    direction: ltr;\n",
       "}\n",
       ".atoms {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".satom,.catom,.patom {\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    border-radius: 0.3em;\n",
       "    border-style: solid;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".sentence {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".clause {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".phrase {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".satom {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 4px;\n",
       "}\n",
       ".catom {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".patom {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".word {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 1px solid #cccccc;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".lex {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 2px solid #888888;\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".satom.l,.catom.l,.patom.l {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".satom.r,.catom.r,.patom.r {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".satom.L,.catom.L,.patom.L {\n",
       "    border-left-style: none\n",
       "}\n",
       ".satom.R,.catom.R,.patom.R {\n",
       "    border-right-style: none\n",
       "}\n",
       ".h,.h :visited,.h :link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".rela,.function,.typ {\n",
       "    font-family: monospace;\n",
       "    font-size: small;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".sp,.sp :visited,.sp :link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".vl {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vvs {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vvt {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".gl {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    color: #aaaaaa;\n",
       "}\n",
       ".vs {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: #444444;\n",
       "}\n",
       ".nd {\n",
       "    font-family: monospace;\n",
       "    font-size: x-small;\n",
       "    color: #999999;\n",
       "}\n",
       ".feat {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0a6611;\n",
       "}\n",
       ".feat .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: x-small;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".hl {\n",
       "    background-color: #ffee66;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import collections, os, sys, random, re\n",
    "from tf.fabric import Fabric\n",
    "from tf.extra.bhsa import Bhsa\n",
    "os.sys.path.append('..')\n",
    "from experiments2 import Experiment\n",
    "from semspace import SemSpace\n",
    "\n",
    "bhsa_data_paths=['~/github/etcbc/bhsa/tf/c',\n",
    "                 '~/github/verb_semantics/project_code/lingo/heads/tf/c',\n",
    "                 '~/github/verb_semantics/project_code/sdbh']\n",
    "\n",
    "TF = Fabric(bhsa_data_paths)\n",
    "tf_api = TF.load('''\n",
    "                function lex vs language\n",
    "                pdp freq_lex gloss domain ls\n",
    "                mother rela typ sp st code txt\n",
    "                heads prep_obj\n",
    "                prs prs_gn prs_nu prs_ps\n",
    "                sem_domain sem_domain_code\n",
    "              ''', silent=True)\n",
    "\n",
    "tf_api.makeAvailableIn(globals())\n",
    "B = Bhsa(api=tf_api, name='', version='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard predicate target template\n",
    "\n",
    "pred_target = '''\n",
    "\n",
    "c1:clause\n",
    "    p1:phrase\n",
    "\n",
    "    /with/\n",
    "    clause typ#Ptcp\n",
    "        p:phrase function={pred_funct}\n",
    "            -heads> word pdp=verb language=Hebrew\n",
    "        p = p1\n",
    "    /or/\n",
    "    clause typ=Ptcp\n",
    "        p:phrase function=PreC|{pred_funct}\n",
    "            -heads> word pdp=verb language=Hebrew\n",
    "        p = p1\n",
    "    /-/\n",
    "\n",
    "        target:word pdp=verb\n",
    "    \n",
    "{basis}\n",
    "\n",
    "lex freq_lex>9\n",
    "   lexword:word \n",
    "   lexword = target\n",
    "'''\n",
    "\n",
    "all_preds = 'Pred|PreO|PreS|PtcO' # all predicate phrase functions\n",
    "\n",
    "def verb_token(target):\n",
    "    # standard verb target tokenizer\n",
    "    vs = F.vs.v(target)\n",
    "    lex = F.lex.v(target)\n",
    "    return f'{lex}.{vs}'\n",
    "\n",
    "good_sem_codes = '1\\.00[1-3][0-9]*|2\\.[0-9]*' # SDBH codes: objects, events, referents, contexts\n",
    "\n",
    "# ordered in terms of selection preferences, select animate first, etc.\n",
    "code_priorities = (('(1\\.001001[0-9]*)',  # ANIMATE\n",
    "                   '(1\\.00300100[3,6])', \n",
    "                   '(1\\.00300101[0,3])',\n",
    "                   '(2\\.075[0-9]*)'),\n",
    "\n",
    "                  ('(1\\.00100[2-6][0-9]*)',  # INANIMATE\n",
    "                   '(1\\.00300100[1-2, 4, 7-9])',\n",
    "                   '(1\\.00300101[1-2])',\n",
    "                   '(1\\.00[1,3]$)',\n",
    "                   '(1\\.00[1,3])\\|',\n",
    "                   '(1\\.003001$)',\n",
    "                   '(1\\.003001)\\|',\n",
    "                   '(1\\.003001005$)', # names of groups (!)\n",
    "                   '(1\\.003001005)\\|',\n",
    "                   '(2\\.[0-9]*)'), # frames\n",
    "    \n",
    "                  ('(1\\.002[0-9]*)', # EVENTS\n",
    "                   '(1\\.003002[0-9]*)',\n",
    "                   '(1\\.002$)',\n",
    "                   '(1\\.002)\\|'))\n",
    "\n",
    "def code2tag(code):\n",
    "    '''\n",
    "    Maps SDBH semantic domains to three basic codes:\n",
    "    animate, inanimate, and events. These codes are\n",
    "    of interest to the semantic content of a verb.\n",
    "    '''\n",
    "    \n",
    "    animate = '|'.join(code_priorities[0])\n",
    "    inanimate = '|'.join(code_priorities[1])\n",
    "    events = '|'.join(code_priorities[2])\n",
    "    \n",
    "    if re.search(animate, code):\n",
    "        return 'animate'\n",
    "    elif re.search(inanimate, code):\n",
    "        return 'inanimate'\n",
    "    elif re.search(events, code):\n",
    "        return 'event'\n",
    "    else:\n",
    "        raise Exception(code) # avoid accidental selections\n",
    "\n",
    "        \n",
    "def code2domain(word):\n",
    "    '''\n",
    "    Selects the prefered SDBH semantic domain code\n",
    "    and maps it to the longer form domain.\n",
    "    '''\n",
    "    \n",
    "    code = F.sem_domain_code.v(word)\n",
    "    domain = F.sem_domain.v(word)\n",
    "    animate = '|'.join(code_priorities[0])\n",
    "    inanimate = '|'.join(code_priorities[1])\n",
    "    events = '|'.join(code_priorities[2])\n",
    "    try:\n",
    "        if re.search(animate, code):\n",
    "            match = next(match for group in re.findall(animate, code) for match in group if match)\n",
    "            code_index = code.split('|').index(match)\n",
    "            return domain.split('|')[code_index]\n",
    "\n",
    "        elif re.search(inanimate, code):\n",
    "            match = next(match for group in re.findall(inanimate, code) for match in group if match)\n",
    "            code_index = code.split('|').index(match)\n",
    "            return domain.split('|')[code_index]\n",
    "\n",
    "        elif re.search(events, code):\n",
    "            match = next(match for group in re.findall(events, code) for match in group if match)\n",
    "            code_index = code.split('|').index(match)   \n",
    "            return domain.split('|')[code_index]\n",
    "        else:\n",
    "            raise Exception(code) # avoid accidental selections\n",
    "    except:\n",
    "        raise Exception(word)\n",
    "\n",
    "    \n",
    "def domainer(basis, target):\n",
    "    # basis tokenizer for semantic domains\n",
    "    sem_category = code2tag(F.sem_domain_code.v(basis))\n",
    "    return sem_category\n",
    "\n",
    "def prep_o_domainer(basis, target):\n",
    "    # makes prep_domain + prep_obj_domain tokens\n",
    "    prep_obj = E.prep_obj.f(basis)[0]\n",
    "    prep_o_domain = code2tag(F.sem_domain_code.v(prep_obj))\n",
    "    return f'{F.lex.v(basis)}_{prep_o_domain}'\n",
    "\n",
    "def lexer(basis, target):\n",
    "    # basis tokenizer for simple lexemes\n",
    "    return F.lex.v(basis)\n",
    "\n",
    "def prep_o_lexer(basis, target):\n",
    "    # makes prep_lex + prep_obj_lex token\n",
    "    prep_obj = E.prep_obj.f(basis)[0]\n",
    "    return f'{F.lex.v(basis)}_{F.lex.v(prep_obj)}'\n",
    "    \n",
    "def nuller(basis, target):\n",
    "    # basis tokenizer for blank values\n",
    "    return 'ø'\n",
    "\n",
    "def functioner(basis, target):\n",
    "    # function basis tokens\n",
    "    return F.function.v(basis)\n",
    "\n",
    "def relationer(basis, target):\n",
    "    # clause relation basis tokens\n",
    "    return F.rela.v(basis)\n",
    "\n",
    "def rela_prep_lexer(basis, target):\n",
    "    # returns clause relation + prep + verb lex\n",
    "    rela = F.rela.v(L.u(basis, 'clause')[0])\n",
    "    prep = next(w for w in L.d(L.u(basis, 'phrase')[0], 'word') if F.pdp.v(w) == 'prep')\n",
    "    prep_lex = F.lex.v(prep)\n",
    "    return f'{rela}.{prep_lex}_{F.lex.v(basis)}'\n",
    "\n",
    "def rela_conj_lexer(basis, target):\n",
    "    # returns clause relation + conjunction string + verb lex\n",
    "    rela = F.rela.v(L.u(basis, 'clause')[0])\n",
    "    conj_phrase = next(ph for ph in L.d(L.u(basis, 'clause')[0], 'phrase') if F.typ.v(ph) == 'CP')\n",
    "    conj_string = ''.join(F.lex.v(w) for w in L.d(conj_phrase, 'word'))\n",
    "    return f'{rela}.{conj_string}_{F.lex.v(basis)}'\n",
    "   \n",
    "def rela_lexer(basis, target):\n",
    "    # returns rela + lex\n",
    "    rela = F.rela.v(L.u(basis, 'clause')[0])\n",
    "    return f'{rela}.{F.lex.v(basis)}'\n",
    "\n",
    "\n",
    "'''\n",
    "Frame Methodology Notes:\n",
    "Within the frame, every capturable element\n",
    "must be present. If there is an uncapturable element, \n",
    "we must exclude the entire clause. Examples of \"uncapturable\n",
    "elements\" are daughter clauses that are verbless without a \n",
    "conjunction. It is not possible to condense these down into\n",
    "a lexical token, as can be done with כאשר + verb, for instance.\n",
    "Thus, not only these clauses, but also their mothers, must be excluded.\n",
    "\n",
    "In order to know which clauses should be excluded, we have\n",
    "to run the whole experiment twice so that every clause relation can be\n",
    "checked and validated. The first time we run it here in this module.\n",
    "\n",
    "The second time the queries are run in the Experiment class to produce results.\n",
    "The results are then crossreferenced against the first run to make sure that all\n",
    "elligible functions are present in the complete result.\n",
    "\n",
    "The class validateFrame (below) completes this task. The data is prepared\n",
    "within the module and is then called to filter the final results.\n",
    "'''\n",
    "\n",
    "class validateFrame:\n",
    "    '''\n",
    "    This class prepares frame validation data\n",
    "    and then filters results based on the prepared\n",
    "    data.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, mother_templates=tuple(), \n",
    "                       daughter_templates=tuple(), \n",
    "                       mother_ri = 0,\n",
    "                       daughter_ri = 3,\n",
    "                       exp_name = ''):\n",
    "    \n",
    "        print(f'Preparing frame validation data for {exp_name}...')\n",
    "\n",
    "        self.good_mothers = set()\n",
    "        self.good_daughters = collections.defaultdict(set)\n",
    "        self.daughter_ri = daughter_ri\n",
    "        self.mother_ri = mother_ri\n",
    "\n",
    "        print(f'\\tpreparing good mother set...')\n",
    "        for mom in mother_templates:\n",
    "            results = set(S.search(mom))\n",
    "            self.good_mothers |= set(r[mother_ri] for r in results) \n",
    "\n",
    "        print(f'\\tpreparing good daughter set...')\n",
    "        for daught in daughter_templates:\n",
    "            results = set(S.search(daught))\n",
    "            for r in results:\n",
    "                rela = F.rela.v(r[daughter_ri])\n",
    "                self.good_daughters[rela].add(r[daughter_ri])\n",
    "\n",
    "        print(f'\\t√ Frame validation data prep complete.')\n",
    "    \n",
    "    def mothers(self, results):\n",
    "        '''\n",
    "        Checks both a mother and her daughters\n",
    "        for validity.\n",
    "        '''\n",
    "        check_relas = set(self.good_daughters.keys())\n",
    "        validated_results = []\n",
    "        for r in results:\n",
    "            mother = r[self.mother_ri]\n",
    "            check_mother_daughters = all([d in self.good_daughters[F.rela.v(d)] for d in E.mother.t(mother)\n",
    "                                              if F.rela.v(d) in check_relas])\n",
    "            if mother in self.good_mothers and check_mother_daughters:\n",
    "                validated_results.append(r)\n",
    "        return validated_results\n",
    "                \n",
    "    def daughters(self, results):\n",
    "        '''\n",
    "        Checks daughters for validity.\n",
    "        '''\n",
    "        check_relas = set(self.good_daughters.keys())\n",
    "        validated_results = []\n",
    "        for r in results:\n",
    "            if all([d in self.good_daughters[F.rela.v(d)] for d in E.mother.t(r[0]) # NB: Assume mother is i=0\n",
    "                        if F.rela.v(d) in check_relas]):\n",
    "                validated_results.append(r)\n",
    "        return validated_results\n",
    "\n",
    "'''\n",
    "The following search templates are specialized for\n",
    "selecting carefully defined clause relations. These\n",
    "templates have been crafted to select elements from the \n",
    "clauses which can easily be lexicalized as basis strings.\n",
    "It excludes a small numer of clause relations that cannot \n",
    "easily be lexicalized, such as verbless clauses without conjunction\n",
    "elements (i.e. כאשר)\n",
    "'''\n",
    "    \n",
    "clR_vc_CP = '''\n",
    "\n",
    "#basis @ 6\n",
    "\n",
    "c2:clause\n",
    "    p1:phrase typ=CP\n",
    "    p2:phrase\n",
    "    /with/\n",
    "    clause kind=VC rela={relas} typ#Ptcp\n",
    "        p3:phrase function=Pred|PreS|PreO\n",
    "        p3 = p2\n",
    "    /or/\n",
    "    clause kind=VC rela={relas} typ=Ptcp\n",
    "        p3:phrase function=PreC|PtcO\n",
    "        p3 = p2\n",
    "    /-/\n",
    "\n",
    "        basis:word pdp=verb {reqs}\n",
    "\n",
    "c1 <mother- c2\n",
    "c2 [[ p2\n",
    "p1 < p2\n",
    "'''\n",
    "\n",
    "clR_vc_prep = '''\n",
    "\n",
    "#basis @ 6\n",
    "\n",
    "c2:clause\n",
    "/without/\n",
    "    phrase typ=CP\n",
    "/-/\n",
    "    p2:phrase\n",
    "    /with/\n",
    "    clause kind=VC rela={relas} typ#Ptcp\n",
    "        p:phrase function=Pred|PreS|PreO\n",
    "        p = p2\n",
    "    /or/\n",
    "    clause kind=VC rela={relas} typ=Ptcp\n",
    "        p:phrase function=PreC|PtcO\n",
    "        p = p2\n",
    "    /-/\n",
    "    \n",
    "        word pdp=prep\n",
    "        < word pdp=verb {reqs} \n",
    "\n",
    "c1 <mother- c2\n",
    "'''\n",
    "\n",
    "clR_vc_verb = '''\n",
    "\n",
    "#basis @ 5\n",
    "\n",
    "c2:clause\n",
    "/without/\n",
    "    phrase typ=CP\n",
    "/-/\n",
    "/without/\n",
    "    word pdp=prin|inrg\n",
    "/-/\n",
    "\n",
    "    p2:phrase\n",
    "    \n",
    "    /with/\n",
    "    clause kind=VC rela={relas} typ#Ptcp\n",
    "        p:phrase function=Pred|PreS|PreO\n",
    "        /without/\n",
    "            word pdp=prep\n",
    "        /-/\n",
    "        p = p2\n",
    "    /or/\n",
    "    clause kind=VC rela={relas} typ=Ptcp\n",
    "        p:phrase function=PreC|PtcO\n",
    "        /without/\n",
    "            word pdp=prep\n",
    "        /-/\n",
    "        p = p2\n",
    "    /-/\n",
    "    \n",
    "        basis:word pdp=verb {reqs}\n",
    "\n",
    "c1 <mother- c2\n",
    "'''\n",
    "\n",
    "clR_nc_CP = '''\n",
    "c2:clause kind=NC rela={relas}\n",
    "    phrase typ=CP\n",
    "    < phrase function=PreC\n",
    "        -heads> word pdp#prep|prps|prde|prin|inrg {reqs}\n",
    "\n",
    "c1 <mother- c2\n",
    "'''\n",
    "\n",
    "clR_nc_PreC_adv = '''\n",
    "#only for use with adj/cmpl relations \n",
    "\n",
    "c2:clause kind=NC rela={relas}\n",
    "/without/\n",
    "    phrase typ=CP\n",
    "/-/\n",
    "    phrase function=PreC typ=AdvP\n",
    "        -heads> word pdp#prep|prps|prde|prin|inrg {reqs}\n",
    "\n",
    "c1 <mother- c2\n",
    "'''\n",
    "\n",
    "clR_nc_PreC_prep = '''\n",
    "#only for use with adj/cmpl functions \n",
    "\n",
    "c2:clause kind=NC rela={relas}\n",
    "/without/\n",
    "    phrase typ=CP\n",
    "/-/\n",
    "    phrase function=PreC typ=PP\n",
    "        -heads> word pdp=prep\n",
    "        -prep_obj> word pdp#prep|prps|prde|prin|inrg {reqs}\n",
    "\n",
    "c1 <mother- c2\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf_clause_conditions = '''\n",
    "\n",
    "c2:clause\n",
    "/without/\n",
    "    phrase function={relas} typ#NP|PrNP|AdvP|PP\n",
    "/-/\n",
    "{clause_reqs}\n",
    "\n",
    "/where/\n",
    "    phrase function={relas} typ#PP\n",
    "/have/\n",
    "    -heads> word pdp#prep|prps|prde|prin|inrg {word_reqs}\n",
    "/-/\n",
    "\n",
    "/where/\n",
    "    phrase function={relas} typ=PP\n",
    "/have/\n",
    "    /where/\n",
    "        -heads> word pdp=prep\n",
    "    /have/\n",
    "        -prep_obj> word pdp#prep|prps|prde|prin|inrg {word_reqs}\n",
    "    /-/\n",
    "/-/\n",
    "\n",
    "c1 = c2\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "vf_all_arg_conditionsSD = vf_clause_conditions.format(relas='Objc|Cmpl|Adju|Time|Loca|PrAd', \n",
    "                                                      word_reqs=f'sem_domain_code~{good_sem_codes}',                                  \n",
    "                                                      clause_reqs='/without/\\n    phrase function=Rela\\n/-/')\n",
    "\n",
    "vf_allarg_sd_np = pred_target.format(basis=f'''\n",
    "\n",
    "{vf_all_arg_conditionsSD}\n",
    "\n",
    "    phrase function=Objc|Cmpl|Adju|Time|Loca|PrAd typ=NP|PrNP|AdvP\n",
    "        -heads> word\n",
    "        \n",
    "''', pred_funct='Pred|PreS')\n",
    "\n",
    "vf_allarg_sd_pp = pred_target.format(basis=f'''\n",
    "\n",
    "{vf_all_arg_conditionsSD}\n",
    "\n",
    "    phrase function=Cmpl|Adju|Time|Loca|PrAd typ=PP\n",
    "        -heads> word\n",
    "        -prep_obj> word\n",
    "        \n",
    "''', pred_funct='Pred|PreS')\n",
    "\n",
    "vf_allarg_sd_pp_obj = pred_target.format(basis=f'''\n",
    "\n",
    "{vf_all_arg_conditionsSD}\n",
    "\n",
    "    phrase function=Objc typ=PP\n",
    "        -heads> word\n",
    "        -prep_obj> word\n",
    "     \n",
    "''', pred_funct='Pred|PreS')\n",
    "\n",
    "# Clause Relations\n",
    "vf_argsSD_cr_vc_CP = pred_target.format(basis=clR_vc_CP.format(relas='Objc|Cmpl|Adju', \n",
    "                                        reqs=f'sem_domain_code~{good_sem_codes}'), \n",
    "                                        pred_funct='Pred|PreS')\n",
    "vf_argsSD_cr_vc_prep = pred_target.format(basis=clR_vc_prep.format(relas='Objc|Cmpl|Adju', \n",
    "                                          reqs=f'sem_domain_code~{good_sem_codes}'),\n",
    "                                          pred_funct='Pred|PreS')\n",
    "vf_argsSD_cr_vc_verb = pred_target.format(basis=clR_vc_verb.format(relas='Objc|Cmpl|Adju', \n",
    "                                          reqs=f'sem_domain_code~{good_sem_codes}'),\n",
    "                                          pred_funct='Pred|PreS')\n",
    "vf_argsSD_cr_nc_CP = pred_target.format(basis=clR_nc_CP.format(relas='Objc|Cmpl|Adju', \n",
    "                                        reqs=f'sem_domain_code~{good_sem_codes}'),\n",
    "                                        pred_funct='Pred|PreS')\n",
    "vf_argsSD_cr_nc_Prec_adv = pred_target.format(basis=clR_nc_PreC_adv.format(relas='Cmpl|Adju',\n",
    "                                              reqs=f'sem_domain_code~{good_sem_codes}'),\n",
    "                                              pred_funct='Pred|PreS')\n",
    "vf_argsSD_cr_nc_Prec_prep = pred_target.format(basis=clR_nc_PreC_prep.format(relas='Cmpl|Adju',\n",
    "                                              reqs=f'sem_domain_code~{good_sem_codes}'),\n",
    "                                              pred_funct='Pred|PreS')\n",
    "\n",
    "# valSD = validateFrame(mother_templates=(vf_allarg_sd_np,\n",
    "#                                         vf_allarg_sd_pp, \n",
    "#                                         vf_allarg_sd_pp_obj),\n",
    "#                       daughter_templates = (vf_argsSD_cr_vc_CP,\n",
    "#                                             vf_argsSD_cr_vc_prep, \n",
    "#                                             vf_argsSD_cr_vc_verb,\n",
    "#                                             vf_argsSD_cr_nc_CP,\n",
    "#                                             vf_argsSD_cr_nc_Prec_adv,\n",
    "#                                             vf_argsSD_cr_nc_Prec_prep),\n",
    "#                       exp_name='vf_allarg_sd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8526 results\n"
     ]
    }
   ],
   "source": [
    "test = B.search(vf_allarg_sd_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "c1:clause\n",
      "    p1:phrase\n",
      "\n",
      "    /with/\n",
      "    clause typ#Ptcp\n",
      "        p:phrase function=Pred|PreS\n",
      "            -heads> word pdp=verb language=Hebrew\n",
      "        p = p1\n",
      "    /or/\n",
      "    clause typ=Ptcp\n",
      "        p:phrase function=PreC|Pred|PreS\n",
      "            -heads> word pdp=verb language=Hebrew\n",
      "        p = p1\n",
      "    /-/\n",
      "\n",
      "        target:word pdp=verb\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "c2:clause\n",
      "/without/\n",
      "    phrase function=Objc|Cmpl|Adju|Time|Loca|PrAd typ#NP|PrNP|AdvP|PP\n",
      "/-/\n",
      "/without/\n",
      "    phrase function=Rela\n",
      "/-/\n",
      "\n",
      "/where/\n",
      "    phrase function=Objc|Cmpl|Adju|Time|Loca|PrAd typ#PP\n",
      "/have/\n",
      "    -heads> word pdp#prep|prps|prde|prin|inrg sem_domain_code~{good_sem_codes}\n",
      "/-/\n",
      "\n",
      "/where/\n",
      "    phrase function=Objc|Cmpl|Adju|Time|Loca|PrAd typ=PP\n",
      "/have/\n",
      "    /where/\n",
      "        -heads> word pdp=prep\n",
      "    /have/\n",
      "        -prep_obj> word pdp#prep|prps|prde|prin|inrg sem_domain_code~{good_sem_codes}\n",
      "    /-/\n",
      "/-/\n",
      "\n",
      "c1 = c2\n",
      "\n",
      "\n",
      "    phrase function=Objc|Cmpl|Adju|Time|Loca|PrAd typ=NP|PrNP|AdvP\n",
      "        -heads> word\n",
      "        \n",
      "\n",
      "\n",
      "lex freq_lex>9\n",
      "   lexword:word \n",
      "   lexword = target\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(vf_allarg_sd_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |     0.00s Feature overview: 111 for nodes; 6 for edges; 1 configs; 7 computed\n",
      "  0.00s Checking search template ...\n",
      "  0.01s Setting up search space for 8 objects ...\n",
      "   |     0.00s \"Quantifier on \"p1:phrase\"\n",
      "   |      |   /with/\n",
      "   |      |   p1:phrase\n",
      "   |      |   clause typ#Ptcp\n",
      "   |      |       p:phrase function=Pred|PreS\n",
      "   |      |           -heads> word pdp=verb language=Hebrew\n",
      "   |      |       p = p1\n",
      "   |      |     1.81s adding 57255 to 0 yields 57255 nodes\n",
      "   |      |   /or/\n",
      "   |      |   p1:phrase\n",
      "   |      |   clause typ=Ptcp\n",
      "   |      |       p:phrase function=PreC|Pred|PreS\n",
      "   |      |           -heads> word pdp=verb language=Hebrew\n",
      "   |      |       p = p1/-/\n",
      "   |      |     1.30s adding 5037 to 57255 yields 62292 nodes\n",
      "   |     1.29s reduction from 253210 to 62292 nodes\n",
      "   |     0.00s \"Quantifier on \"c2:clause\"\n",
      "   |      |   /without/\n",
      "   |      |   c2:clause\n",
      "   |      |       phrase function=Objc|Cmpl|Adju|Time|Loca|PrAd typ#NP|PrNP|AdvP|PP\n",
      "   |      |   /-/\n",
      "   |      |     0.35s 489 nodes to exclude\n",
      "   |     0.35s reduction from 88123 to 87634 nodes\n",
      "   |     0.00s \"Quantifier on \"c2:clause\"\n",
      "   |      |   /without/\n",
      "   |      |   c2:clause\n",
      "   |      |       phrase function=Rela\n",
      "   |      |   /-/\n",
      "   |      |     0.30s 6328 nodes to exclude\n",
      "   |     0.30s reduction from 87634 to 81310 nodes\n",
      "   |     0.00s \"Quantifier on \"c2:clause\"\n",
      "   |      |   /where/\n",
      "   |      |   c2:clause\n",
      "   |      |       phrase function=Objc|Cmpl|Adju|Time|Loca|PrAd typ#PP\n",
      "   |      |     0.45s 18048 matching nodes\n",
      "   |      |   /have/\n",
      "   |      |   c2:clause\n",
      "   |      |       phrase function=Objc|Cmpl|Adju|Time|Loca|PrAd typ#PP\n",
      "   |      |       -heads> word pdp#prep|prps|prde|prin|inrg sem_domain_code~{good_sem_codes}\n",
      "   |      |   /-/\n",
      "   |      |     1.18s 0 matching nodes\n",
      "   |      |     1.19s 17258 match antecedent but not consequent\n",
      "   |     1.19s reduction from 81310 to 65125 nodes\n",
      "   |     0.00s \"Quantifier on \"c2:clause\"\n",
      "   |      |   /where/\n",
      "   |      |   c2:clause\n",
      "   |      |       phrase function=Objc|Cmpl|Adju|Time|Loca|PrAd typ=PP\n",
      "   |      |     0.59s 51112 matching nodes\n",
      "   |      |   /have/\n",
      "   |      |   c2:clause\n",
      "   |      |       phrase function=Objc|Cmpl|Adju|Time|Loca|PrAd typ=PP\n",
      "   |      |       /where/\n",
      "   |      |           -heads> word pdp=prep\n",
      "   |      |       /have/\n",
      "   |      |           -prep_obj> word pdp#prep|prps|prde|prin|inrg sem_domain_code~{good_sem_codes}\n",
      "   |      |       /-/\n",
      "   |      |   /-/\n",
      "   |      |     0.00s \"Quantifier on \"parent:phrase function=Objc|Cmpl|Adju|Time|Loca|PrAd typ=PP\"\n",
      "   |      |      |   /where/\n",
      "   |      |      |   parent:phrase function=Objc|Cmpl|Adju|Time|Loca|PrAd typ=PP\n",
      "   |      |      |       -heads> word pdp=prep\n",
      "   |      |      |     1.20s 54825 matching nodes\n",
      "   |      |      |   /have/\n",
      "   |      |      |   parent:phrase function=Objc|Cmpl|Adju|Time|Loca|PrAd typ=PP\n",
      "   |      |      |       -heads> word pdp=prep\n",
      "   |      |      |       -prep_obj> word pdp#prep|prps|prde|prin|inrg sem_domain_code~{good_sem_codes}\n",
      "   |      |      |   /-/\n",
      "   |      |      |     1.61s 0 matching nodes\n",
      "   |      |      |     1.63s 51112 match antecedent but not consequent\n",
      "   |      |     2.86s reduction from 51112 to 0 nodes\n",
      "   |      |     2.87s 0 matching nodes\n",
      "   |      |     2.89s 42878 match antecedent but not consequent\n",
      "   |     1.66s reduction from 65125 to 33347 nodes\n",
      "  2.16s Constraining search space with 8 relations ...\n",
      "  2.20s Setting up retrieval plan ...\n",
      "  2.23s Ready to deliver results from 1075048 nodes\n",
      "Iterate over S.fetch() to get the results\n",
      "See S.showPlan() to interpret the results\n"
     ]
    }
   ],
   "source": [
    "S.study(vf_allarg_sd_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
