{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration and Prep of SDBH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections, Levenshtein, re\n",
    "import xml.etree.ElementTree as ET\n",
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 4.1.2\n",
      "Api reference : https://dans-labs.github.io/text-fabric/Api/General/\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "114 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.01s B book                 from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.01s B chapter              from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.01s B verse                from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.14s B lex_utf8             from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s B qere                 from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.11s B lex                  from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.01s B voc_lex_utf8         from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.11s B pdp                  from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s Feature overview: 109 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  4.13s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations='~/github/etcbc/bhsa/tf/c')\n",
    "api = TF.load('''\n",
    "              book chapter verse\n",
    "              lex qere \n",
    "              voc_lex_utf8\n",
    "              lex_utf8 pdp\n",
    "              ''')\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdbh_resource = '/Users/cody/github/marble-lexicon/SDBH/SDBH.XML'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdbh_tree = ET.parse(sdbh_resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = sdbh_tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion To TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map SDBH Domains to Domain Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = '/Users/cody/github/marble-lexicon/SDBH/SDBH.DM1'\n",
    "domains2 = '/Users/cody/github/marble-lexicon/SDBH/SDBH.DM2'\n",
    "\n",
    "domain2code = {}\n",
    "\n",
    "with open(domains, 'r') as infile:\n",
    "    domains = [dm.split('\\\\') + ['version 1'] for dm in infile.read().split('\\n\\n') \n",
    "                   if ''.join(dm.split('\\\\'))] # <- avoid null lines\n",
    "\n",
    "with open(domains2, 'r') as infile2:\n",
    "    domains.extend([dm.split('\\\\') + ['version 2'] for dm in infile2.read().split('\\n\\n') \n",
    "                       if ''.join(dm.split('\\\\'))] \n",
    "                  )\n",
    "    \n",
    "for i, dom in enumerate(domains):\n",
    "    dom_data = dict((data.split(' ', 1)[0], data.split(' ', 1)[1]) for data in dom\n",
    "                        if data.split())\n",
    "    \n",
    "    if 'label' in dom_data and 'code' in dom_data:          \n",
    "        domain2code[dom_data['label'].strip()] = dom_data['version'] + '.' + dom_data['code'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.020003'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain2code['Body > Status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Lexical Domains to Verse and Word References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref2domains = collections.defaultdict(dict)\n",
    "\n",
    "for entry in root.findall('Lexicon_Entry'):\n",
    "    \n",
    "    this_lex = entry.attrib['Lemma']\n",
    "    \n",
    "    for meaning in entry.findall('BaseForms/BaseForm/LEXMeanings/'):\n",
    "        \n",
    "        domains = [mean.text for mean in meaning.findall('LEXDomains/LEXDomain')]\n",
    "        domains = [word for word in domains \n",
    "                      if word in domain2code]\n",
    "        \n",
    "        domains = '|'.join(domains)\n",
    "        \n",
    "        if not domains: # try again\n",
    "            domains = [mean.text for mean in meaning.findall('LEXDomains/LEXDomain')]\n",
    "            domains = [word for domstring in domains \n",
    "                          for word in domstring.split()\n",
    "                          if word in domain2code]\n",
    "            domains = '|'.join(domains)\n",
    "            \n",
    "            if not domains: # give up\n",
    "                continue\n",
    "            \n",
    "        for ref in meaning.findall('LEXReferences/LEXReference'):\n",
    "\n",
    "            ref2domains[ref.text[:14]][this_lex] = domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'אִישׁ': 'People'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref2domains['00100202300042'] # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.001001002003'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain2code['People']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Conversion Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = '''Genesis\n",
    "Exodus\n",
    "Leviticus\n",
    "Numbers\n",
    "Deuteronomy\n",
    "Joshua\n",
    "Judges\n",
    "Ruth\n",
    "1_Samuel\n",
    "2_Samuel\n",
    "1_Kings\n",
    "2_Kings\n",
    "1_Chronicles\n",
    "2_Chronicles\n",
    "Ezra\n",
    "Nehemiah\n",
    "Esther\n",
    "Job\n",
    "Psalms\n",
    "Proverbs\n",
    "Ecclesiastes\n",
    "Song_of_songs\n",
    "Isaiah\n",
    "Jeremiah\n",
    "Lamentations\n",
    "Ezekiel\n",
    "Daniel\n",
    "Hosea\n",
    "Joel\n",
    "Amos\n",
    "Obadiah\n",
    "Jonah\n",
    "Micah\n",
    "Nahum\n",
    "Habakkuk\n",
    "Zephaniah\n",
    "Haggai\n",
    "Zechariah\n",
    "Malachi'''.split('\\n')\n",
    "\n",
    "books = dict((i+1, book) for i, book in enumerate(books))\n",
    "consonants = set(letter for w in F.otype.s('word')\n",
    "                 for letter in F.lex_utf8.v(w))\n",
    "consonants = list(consonants)\n",
    "consonants.remove('ׁ')\n",
    "consonants.remove('ׂ')\n",
    "#consonants.append()\n",
    "\n",
    "finals = {'ם': 'מ',\n",
    "          'ן' : 'נ',\n",
    "          'ך' : 'כ',\n",
    "          'ף' : 'פ',\n",
    "          'ץ' : 'צ'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip(word_string):\n",
    "    '''\n",
    "    strips all accentuations\n",
    "    '''\n",
    "    word_string = word_string.replace('־', ' ')\n",
    "    for final in finals:\n",
    "        word_string = word_string.replace(final, finals[final])\n",
    "    return ''.join(w for w in word_string if w in consonants)\n",
    "\n",
    "def with_qere_words(verse, option=1):\n",
    "    \n",
    "    '''\n",
    "    Returns a list of word nodes\n",
    "    where words are repeated in the\n",
    "    case of a qere reading.\n",
    "    '''\n",
    "    \n",
    "    words = L.d(verse, 'word')\n",
    "    qeres = [w for w in words if F.qere.v(w)]\n",
    "    \n",
    "    qeres_count = [(qeres[i+1] - w if i+1 < len(qeres) else 0) for i, w in enumerate(qeres)\n",
    "                      ]\n",
    "    \n",
    "    if option == 1:\n",
    "        for qe, ct in zip(qeres, qeres_count):\n",
    "            if ct != 1:\n",
    "                index = words.index(qe) + 1\n",
    "                words.insert(index, qe)\n",
    "                \n",
    "    elif option == 2:\n",
    "        for qe in qeres:\n",
    "            index = words.index(qe) + 1\n",
    "            words.insert(index, qe)\n",
    "                    \n",
    "    return words\n",
    "    \n",
    "def look_around(word_node, target_lex, window=4):\n",
    "    '''\n",
    "    A last ditch option for lex matching.\n",
    "    Looks ahead and behind n words.\n",
    "    '''\n",
    "    \n",
    "    verse_words = L.d(L.u(word_node, 'verse')[0], 'word')\n",
    "    nodes = [word_node+i for i in range(-window, window)\n",
    "                if word_node+i in verse_words\n",
    "                and Levenshtein.ratio(strip(F.voc_lex_utf8.v(L.u(word_node+i, 'lex')[0])), target_lex) > 0.7]\n",
    "    \n",
    "    if nodes:\n",
    "        return nodes[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def get_node(ref_string, qere_option=1):\n",
    "    \n",
    "    '''\n",
    "    Uses an SDBH reference ID to\n",
    "    find the corresponding Text-Fabric \n",
    "    word node.\n",
    "    '''\n",
    "\n",
    "    book = books[round(int(ref_string[:3]))]\n",
    "    chapt = round(int(ref_string[3:6]))\n",
    "    verse = round(int(ref_string[6:9]))\n",
    "    word = int(round(int(ref_string[-3:])) / 2) - 1\n",
    "    verse_node = T.nodeFromSection((book, chapt, verse))\n",
    "    verse_words = with_qere_words(verse_node, option=qere_option)\n",
    "    word_node = verse_words[word]\n",
    "    \n",
    "#     if ref_string == '00902000200052':\n",
    "#         print(f'looking at pos {word}')\n",
    "#         print(T.text([word_node]))\n",
    "#         for i, w in enumerate(verse_words):\n",
    "#             print(i, w, T.text([w]))\n",
    "\n",
    "    return word_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map & Export Domains and Domain Codes to TF Word Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exceptions: 1867\n",
      "good matches 264305\n"
     ]
    }
   ],
   "source": [
    "word2domain = {}\n",
    "exceptions = []\n",
    "\n",
    "for ref, data in ref2domains.items():\n",
    "    \n",
    "    for lex, domains in data.items():    \n",
    "            \n",
    "        if not domains:\n",
    "            continue\n",
    "            \n",
    "        lex = strip(lex)\n",
    "            \n",
    "        try:\n",
    "            wordnode = get_node(ref)\n",
    "            etcbc_lex = strip(F.lex_utf8.v(wordnode))\n",
    "\n",
    "            if Levenshtein.ratio(etcbc_lex, lex) > 0.7 or etcbc_lex in lex or lex in etcbc_lex:\n",
    "                word2domain[wordnode] = domains\n",
    "                continue\n",
    "\n",
    "            # try a second time with alternative qere disambig\n",
    "            wordnode = get_node(ref, qere_option=2)\n",
    "            etcbc_lex = strip(F.lex_utf8.v(wordnode))\n",
    "            if Levenshtein.ratio(etcbc_lex, lex) > 0.7 or etcbc_lex in lex or lex in etcbc_lex:\n",
    "                word2domain[wordnode] = domains\n",
    "                \n",
    "            elif look_around(wordnode, lex):\n",
    "                word2domain[look_around(wordnode, lex)] = domains\n",
    "                \n",
    "            else:\n",
    "                exceptions.append((f'{ref}: unmatched lex: SBDH {lex} ≠ ETCBC {etcbc_lex}'))\n",
    "\n",
    "        except:\n",
    "            \n",
    "            try:\n",
    "                wordnode = get_node(ref, qere_option=2)\n",
    "                etcbc_lex = strip(F.lex_utf8.v(wordnode))\n",
    "                if Levenshtein.ratio(etcbc_lex, lex) > 0.7 or etcbc_lex in lex or lex in etcbc_lex:\n",
    "                    word2domain[wordnode] = domains\n",
    "                \n",
    "            except Exception as e:\n",
    "                exceptions.append((f'{ref}: {e}; SBDH lex {lex}'))\n",
    "    \n",
    "print('exceptions:', len(exceptions))\n",
    "print('good matches', len(word2domain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02002702000010: unmatched lex: SBDH אבדונ ≠ ETCBC אבדה',\n",
       " '02003100400030: unmatched lex: SBDH או ≠ ETCBC אי',\n",
       " '02003100400032: unmatched lex: SBDH אוה ≠ ETCBC אי',\n",
       " '00502601400008: unmatched lex: SBDH אוני ≠ ETCBC אנה',\n",
       " '02800900400026: unmatched lex: SBDH אוני ≠ ETCBC אנה',\n",
       " '02302601900024: unmatched lex: SBDH אורה ≠ ETCBC ארת',\n",
       " '01200403900018: unmatched lex: SBDH אורה ≠ ETCBC ארת',\n",
       " '01403202800042: unmatched lex: SBDH אורה ≠ ETCBC אורות',\n",
       " '02602102100002: unmatched lex: SBDH חדד ≠ ETCBC אחד',\n",
       " '02604004400032: unmatched lex: SBDH אחד ≠ ETCBC אשר']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exceptions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Troubleshooting Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = '00100900500040'\n",
    "pbook = books[round(int(problem[:3]))]\n",
    "pchapt = round(int(problem[3:6]))\n",
    "pverse = round(int(problem[6:9]))\n",
    "pword = int(round(int(problem[-3:])) / 2) - 1\n",
    "\n",
    "test = T.nodeFromSection((pbook, pchapt, pverse))\n",
    "\n",
    "test_words = with_qere_words(test, option=2)\n",
    "\n",
    "# print(f'problem at {pbook} {pchapt}:{pverse}, {test}')\n",
    "# print(f'seeking word at pos {pword}\\n')\n",
    "\n",
    "# for i, w in enumerate(test_words):\n",
    "#     lex = L.u(w, 'lex')[0]\n",
    "#     print(i, w, F.lex_utf8.v(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map domains to codes to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264305"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2code = {}\n",
    "\n",
    "for w, domains in word2domain.items():\n",
    "\n",
    "    \n",
    "    if '>' in domains:\n",
    "        print(domains)\n",
    "        break\n",
    "    \n",
    "    domains = [word for word in domains.split('|')]\n",
    "\n",
    "    codes = '|'.join(domain2code.get(dom, '') for dom in domains)\n",
    "    \n",
    "    if codes:\n",
    "        word2code[w] = codes\n",
    "        \n",
    "len(word2code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'People'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2domain[1136]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Good Matches to TF Resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s Feature \"otype\" not available in\n",
      "/Users/cody/github/semantics/project_code/sdbh/\n",
      "  0.00s Not all features could be loaded/computed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |     0.46s T sem_domain           to /Users/cody/github/semantics/project_code/sdbh\n",
      "   |     0.47s T sem_domain_code      to /Users/cody/github/semantics/project_code/sdbh\n",
      "EXPORT DONE!\n"
     ]
    }
   ],
   "source": [
    "meta = {'': {'created_by': 'Renier de Blois (UBS)',\n",
    "         'coreData': 'BHSA',\n",
    "         'coreVersion': 'c'\n",
    "        },\n",
    "        \n",
    "    'sem_domain_code' : {'source': 'Exported from the SDBL.XML',\n",
    "                    'valueType': 'str'},\n",
    "        \n",
    "    'sem_domain': {'source': 'Exported from the SDBL.XML',\n",
    "              'valueType': 'str'}\n",
    "   }\n",
    "\n",
    "newFeatures = {'sem_domain_code': word2code,\n",
    "               'sem_domain': word2domain\n",
    "              }\n",
    "\n",
    "save_TF = Fabric(locations='~/github/semantics/project_code/sdbh', silent=True)\n",
    "api = save_TF.load('', silent=True)\n",
    "\n",
    "save_TF.save(nodeFeatures=newFeatures, edgeFeatures={}, metaData=meta)\n",
    "print('EXPORT DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 4.1.2\n",
      "Api reference : https://dans-labs.github.io/text-fabric/Api/General/\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "116 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.01s B book                 from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s B chapter              from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s B verse                from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.14s B lex_utf8             from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s B qere                 from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.11s B lex                  from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s B voc_lex_utf8         from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.11s B pdp                  from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.81s T sem_domain           from /Users/cody/github/semantics/project_code/sdbh\n",
      "   |     0.89s T sem_domain_code      from /Users/cody/github/semantics/project_code/sdbh\n",
      "   |     0.00s B gloss                from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s Feature overview: 111 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  6.18s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations=['~/github/etcbc/bhsa/tf/c', '~/github/semantics/project_code/sdbh'])\n",
    "api = TF.load('''\n",
    "              book chapter verse\n",
    "              lex qere \n",
    "              voc_lex_utf8\n",
    "              lex_utf8 pdp\n",
    "              sem_domain \n",
    "              sem_domain_code \n",
    "              gloss\n",
    "              ''')\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "בָּרָ֣א  Exist\n",
      "אֱלֹהִ֑ים  Deities\n",
      "אֵ֥ת  Identifiers\n",
      "שָּׁמַ֖יִם  Universe\n",
      "אֵ֥ת  Identifiers\n",
      "אָֽרֶץ׃  Land\n",
      "אָ֗רֶץ  Land\n",
      "הָיְתָ֥ה  Exist\n",
      "תֹ֨הוּ֙  Non-Exist\n",
      "בֹ֔הוּ  Non-Exist\n",
      "חֹ֖שֶׁךְ  Dark\n",
      "עַל־ Location\n",
      "תְהֹ֑ום  Waterbodies\n",
      "ר֣וּחַ  Spirit|Deities\n",
      "אֱלֹהִ֔ים  Deities|Intense\n",
      "מְרַחֶ֖פֶת  Move\n",
      "עַל־ Location\n",
      "מָּֽיִם׃  Liquids\n",
      "יֹּ֥אמֶר  Speak\n",
      "אֱלֹהִ֖ים  Deities\n",
      "יְהִ֣י  Exist\n",
      "אֹ֑ור  Shine\n",
      "יְהִי־ Exist\n",
      "אֹֽור׃  Shine\n",
      "יַּ֧רְא  See\n",
      "אֱלֹהִ֛ים  Deities\n",
      "אֶת־ Identifiers\n",
      "אֹ֖ור  Shine\n",
      "כִּי־ Perception\n",
      "יַּבְדֵּ֣ל  Divide\n",
      "אֱלֹהִ֔ים  Deities\n",
      "בֵּ֥ין  Occurrence\n",
      "אֹ֖ור  Shine\n",
      "בֵ֥ין  Occurrence\n",
      "חֹֽשֶׁךְ׃  Dark\n",
      "יִּקְרָ֨א  Speak\n",
      "אֱלֹהִ֤ים׀  Deities\n",
      "אֹור֙  Shine\n",
      "יֹ֔ום  Shine|Universe|Time\n",
      "חֹ֖שֶׁךְ  Dark\n",
      "קָ֣רָא  Speak\n",
      "לָ֑יְלָה  Time\n",
      "יְהִי־ Happen\n",
      "עֶ֥רֶב  Time\n",
      "יְהִי־ Happen\n",
      "בֹ֖קֶר  Time\n",
      "יֹ֥ום  Time\n",
      "אֶחָֽד׃ פ  Quantity|Frequency\n",
      "יֹּ֣אמֶר  Speak\n",
      "אֱלֹהִ֔ים  Deities\n",
      "יְהִ֥י  Exist\n",
      "רָקִ֖יעַ  Universe\n",
      "בְּ Location\n",
      "תֹ֣וךְ  Orientation\n",
      "מָּ֑יִם  Liquids\n",
      "יהִ֣י  Events\n",
      "מַבְדִּ֔יל  Divide\n",
      "בֵּ֥ין  Location\n",
      "מַ֖יִם  Liquids\n",
      "מָֽיִם׃  Liquids\n",
      "יַּ֣עַשׂ  Exist\n",
      "אֱלֹהִים֮  Deities\n",
      "אֶת־ Identifiers\n",
      "רָקִיעַ֒  Universe\n",
      "יַּבְדֵּ֗ל  Divide\n",
      "בֵּ֤ין  Location\n",
      "מַּ֨יִם֙  Liquids\n",
      "אֲשֶׁר֙  Description\n",
      "רָקִ֔יעַ  Universe\n",
      "בֵ֣ין  Location\n",
      "מַּ֔יִם  Liquids\n",
      "אֲשֶׁ֖ר  Description\n",
      "עַ֣ל  Location\n",
      "רָקִ֑יעַ  Universe\n",
      "יְהִי־ Happen\n",
      "כֵֽן׃  Referents\n",
      "יִּקְרָ֧א  Speak\n",
      "אֱלֹהִ֛ים  Deities\n",
      "רָקִ֖יעַ  Universe\n",
      "שָׁמָ֑יִם  Universe\n",
      "יְהִי־ Happen\n",
      "עֶ֥רֶב  Time\n",
      "יְהִי־ Happen\n",
      "בֹ֖קֶר  Time\n",
      "יֹ֥ום  Time\n",
      "שֵׁנִֽי׃ פ  Quantity|Frequency\n",
      "יֹּ֣אמֶר  Speak\n",
      "אֱלֹהִ֗ים  Deities\n",
      "יִקָּו֨וּ  Gather\n",
      "מַּ֜יִם  Liquids\n",
      "שָּׁמַ֨יִם֙  Universe\n",
      "אֶל־ Location\n",
      "מָקֹ֣ום  Space\n",
      "אֶחָ֔ד  Quantity|Frequency\n",
      "תֵרָאֶ֖ה  See\n",
      "יַּבָּשָׁ֑ה  Dry\n",
      "יְהִי־ Happen\n",
      "כֵֽן׃  Referents\n",
      "יִּקְרָ֨א  Speak\n",
      "אֱלֹהִ֤ים׀  Deities\n",
      "יַּבָּשָׁה֙  Dry\n",
      "אֶ֔רֶץ  Land\n",
      "מִקְוֵ֥ה  Gather\n",
      "מַּ֖יִם  Liquids\n",
      "קָרָ֣א  Speak\n",
      "יַמִּ֑ים  Waterbodies\n",
      "יַּ֥רְא  See\n",
      "אֱלֹהִ֖ים  Deities\n",
      "כִּי־ Perception\n",
      "יֹּ֣אמֶר  Speak\n",
      "אֱלֹהִ֗ים  Deities\n",
      "תַּֽדְשֵׁ֤א  Stage\n",
      "אָ֨רֶץ֙  Land\n",
      "דֶּ֔שֶׁא  Plants\n",
      "עֵ֚שֶׂב  Crops\n",
      "מַזְרִ֣יעַ  Plant|Exist\n",
      "זֶ֔רַע  Plants\n",
      "עֵ֣ץ  Trees\n",
      "פְּרִ֞י  Fruits\n",
      "עֹ֤שֶׂה  Exist\n",
      "פְּרִי֙  Fruits\n",
      "מִינֹ֔ו  Description\n",
      "אֲשֶׁ֥ר  Description\n",
      "זַרְעֹו־ Plants\n",
      "בֹ֖ו  Location\n",
      "עַל־ Location\n",
      "אָ֑רֶץ  Land\n",
      "יְהִי־ Happen\n",
      "כֵֽן׃  Referents\n",
      "אָ֜רֶץ  Land\n",
      "דֶּ֠שֶׁא  Plants\n",
      "עֵ֣שֶׂב  Crops\n",
      "מַזְרִ֤יעַ  Plant|Exist\n",
      "זֶ֨רַע֙  Plants\n",
      "מִינֵ֔הוּ  Description\n",
      "עֵ֧ץ  Trees\n",
      "עֹ֥שֶׂה  Exist\n",
      "פְּרִ֛י  Fruits\n",
      "אֲשֶׁ֥ר  Description\n",
      "זַרְעֹו־ Plants\n",
      "בֹ֖ו  Location\n",
      "מִינֵ֑הוּ  Description\n",
      "יַּ֥רְא  See\n",
      "אֱלֹהִ֖ים  Deities\n",
      "כִּי־ Perception\n",
      "יְהִי־ Happen\n",
      "עֶ֥רֶב  Time\n",
      "יְהִי־ Happen\n",
      "בֹ֖קֶר  Time\n",
      "יֹ֥ום  Time\n",
      "שְׁלִישִֽׁי׃ פ  Quantity|Frequency\n",
      "יֹּ֣אמֶר  Speak\n",
      "אֱלֹהִ֗ים  Deities\n",
      "יְהִ֤י  Exist\n",
      "מְאֹרֹת֙  Shine\n",
      "בִּ Location\n",
      "רְקִ֣יעַ  Universe\n",
      "שָּׁמַ֔יִם  Universe\n",
      "הַבְדִּ֕יל  Divide\n",
      "בֵּ֥ין  Occurrence\n",
      "יֹּ֖ום  Time|Shine\n",
      "בֵ֣ין  Occurrence\n",
      "לָּ֑יְלָה  Time\n",
      "הָי֤וּ  Identifiers\n",
      "אֹתֹת֙  Know\n",
      "מֹ֣ועֲדִ֔ים  Time\n",
      "יָמִ֖ים  Time\n",
      "הָי֤וּ  Identifiers\n",
      "מְאֹורֹת֙  Shine\n",
      "בִּ Location\n",
      "רְקִ֣יעַ  Universe\n",
      "שָּׁמַ֔יִם  Universe\n",
      "הָאִ֖יר  Shine\n",
      "עַל־ Location\n",
      "אָ֑רֶץ  Land\n",
      "יְהִי־ Happen\n",
      "כֵֽן׃  Referents\n",
      "יַּ֣עַשׂ  Exist\n",
      "אֱלֹהִ֔ים  Deities\n",
      "אֶת־ Identifiers\n",
      "שְׁנֵ֥י  Quantity|Frequency\n",
      "מְּאֹרֹ֖ת  Shine\n",
      "גְּדֹלִ֑ים  Large\n",
      "אֶת־ Identifiers\n",
      "מָּאֹ֤ור  Shine\n",
      "גָּדֹל֙  Large\n",
      "מֶמְשֶׁ֣לֶת  Control\n",
      "יֹּ֔ום  Time|Shine\n",
      "אֶת־ Identifiers\n",
      "מָּאֹ֤ור  Shine\n",
      "קָּטֹן֙  Little\n",
      "מֶמְשֶׁ֣לֶת  Control\n",
      "לַּ֔יְלָה  Time\n",
      "אֵ֖ת  Identifiers\n",
      "כֹּוכָבִֽים׃  Universe\n",
      "יִּתֵּ֥ן  Possess\n",
      "אֹתָ֛ם  Identifiers\n",
      "אֱלֹהִ֖ים  Deities\n",
      "בִּ Location\n",
      "רְקִ֣יעַ  Universe\n",
      "שָּׁמָ֑יִם  Universe\n",
      "הָאִ֖יר  Shine\n",
      "עַל־ Location\n",
      "אָֽרֶץ׃  Land\n",
      "מְשֹׁל֙  Control\n",
      "יֹּ֣ום  Time|Shine\n",
      "לַּ֔יְלָה  Time\n",
      "הַבְדִּ֔יל  Divide\n",
      "בֵּ֥ין  Occurrence\n",
      "אֹ֖ור  Shine\n",
      "בֵ֣ין  Occurrence\n",
      "חֹ֑שֶׁךְ  Dark\n",
      "יַּ֥רְא  See\n",
      "אֱלֹהִ֖ים  Deities\n",
      "כִּי־ Perception\n",
      "יְהִי־ Happen\n",
      "עֶ֥רֶב  Time\n",
      "יְהִי־ Happen\n",
      "בֹ֖קֶר  Time\n",
      "יֹ֥ום  Time\n",
      "רְבִיעִֽי׃ פ  Quantity|Frequency\n",
      "יֹּ֣אמֶר  Speak\n",
      "אֱלֹהִ֔ים  Deities\n",
      "יִשְׁרְצ֣וּ  Space\n",
      "מַּ֔יִם  Liquids\n",
      "שֶׁ֖רֶץ  Swarming Creatures\n",
      "נֶ֣פֶשׁ  Creatures\n",
      "חַיָּ֑ה  Alive\n",
      "עֹוף֙  Birds\n",
      "יְעֹופֵ֣ף  Move\n",
      "עַל־ Location\n",
      "אָ֔רֶץ  Land\n",
      "עַל־ Location\n",
      "רְקִ֥יעַ  Universe\n",
      "שָּׁמָֽיִם׃  Universe\n",
      "יִּבְרָ֣א  Exist\n",
      "אֱלֹהִ֔ים  Deities\n",
      "אֶת־ Identifiers\n",
      "תַּנִּינִ֖ם  Aquatic Animals\n",
      "גְּדֹלִ֑ים  Large\n",
      "אֵ֣ת  Identifiers\n",
      "כָּל־ Complete\n",
      "נֶ֣פֶשׁ  Creatures\n",
      "חַיָּ֣ה׀  Alive\n",
      "רֹמֶ֡שֶׂת  Move\n",
      "אֲשֶׁר֩  Description\n",
      "שָׁרְצ֨וּ  Space\n",
      "מַּ֜יִם  Liquids\n",
      "מִֽינֵהֶ֗ם  Description\n",
      "אֵ֨ת  Identifiers\n",
      "כָּל־ Complete\n",
      "עֹ֤וף  Birds\n",
      "כָּנָף֙  Creatures\n",
      "מִינֵ֔הוּ  Description\n",
      "יַּ֥רְא  See\n",
      "אֱלֹהִ֖ים  Deities\n",
      "כִּי־ Perception\n",
      "יְבָ֧רֶךְ  Bless\n",
      "אֹתָ֛ם  Identifiers\n",
      "אֱלֹהִ֖ים  Deities\n",
      "אמֹ֑ר  Speak\n",
      "פְּר֣וּ  Quantity\n",
      "רְב֗וּ  Quantity|Frequency\n",
      "מִלְא֤וּ  Contain\n",
      "אֶת־ Identifiers\n",
      "מַּ֨יִם֙  Liquids\n",
      "בַּ Location\n",
      "יַּמִּ֔ים  Waterbodies\n",
      "עֹ֖וף  Birds\n",
      "יִ֥רֶב  Quantity|Frequency\n",
      "בָּ Location\n",
      "אָֽרֶץ׃  Land\n",
      "יְהִי־ Happen\n",
      "עֶ֥רֶב  Time\n",
      "יְהִי־ Happen\n",
      "בֹ֖קֶר  Time\n",
      "יֹ֥ום  Time\n",
      "חֲמִישִֽׁי׃ פ  Quantity|Frequency\n",
      "יֹּ֣אמֶר  Speak\n",
      "אֱלֹהִ֗ים  Deities\n",
      "אָ֜רֶץ  Land\n",
      "נֶ֤פֶשׁ  Creatures\n",
      "חַיָּה֙  Alive\n",
      "מִינָ֔הּ  Description\n",
      "בְּהֵמָ֥ה  Domestic Animals\n",
      "רֶ֛מֶשׂ  Small Animals\n",
      "חַֽיְתֹו־ Alive|Animals\n",
      "אֶ֖רֶץ  Land\n",
      "מִינָ֑הּ  Description\n",
      "יְהִי־ Happen\n",
      "כֵֽן׃  Referents\n",
      "יַּ֣עַשׂ  Exist\n",
      "אֱלֹהִים֩  Deities\n",
      "אֶת־ Identifiers\n",
      "חַיַּ֨ת  Alive|Animals\n",
      "אָ֜רֶץ  Land\n",
      "מִינָ֗הּ  Description\n",
      "אֶת־ Identifiers\n",
      "בְּהֵמָה֙  Domestic Animals\n",
      "מִינָ֔הּ  Description\n",
      "אֵ֛ת  Identifiers\n",
      "כָּל־ Complete\n",
      "רֶ֥מֶשׂ  Small Animals\n",
      "אֲדָמָ֖ה  Land\n",
      "מִינֵ֑הוּ  Description\n",
      "יַּ֥רְא  See\n",
      "אֱלֹהִ֖ים  Deities\n",
      "כִּי־ Perception\n",
      "יֹּ֣אמֶר  Speak\n",
      "אֱלֹהִ֔ים  Deities\n",
      "נַֽעֲשֶׂ֥ה  Exist\n",
      "אָדָ֛ם  People\n",
      "צַלְמֵ֖נוּ  Compare\n",
      "דְמוּתֵ֑נוּ  Compare\n",
      "יִרְדּוּ֩  Control\n",
      "דְגַ֨ת  Aquatic Animals\n",
      "יָּ֜ם  Waterbodies\n",
      "עֹ֣וף  Birds\n",
      "שָּׁמַ֗יִם  Universe\n",
      "בְּהֵמָה֙  Domestic Animals\n",
      "כָל־ Complete\n",
      "אָ֔רֶץ  Land\n",
      "כָל־ Complete\n",
      "רֶ֖מֶשׂ  Small Animals\n",
      "רֹמֵ֥שׂ  Move\n",
      "עַל־ Location\n",
      "אָֽרֶץ׃  Land\n",
      "יִּבְרָ֨א  Exist\n",
      "אֱלֹהִ֤ים׀  Deities\n",
      "אֶת־ Identifiers\n",
      "אָדָם֙  People\n",
      "צַלְמֹ֔ו  Compare\n",
      "צֶ֥לֶם  Compare\n",
      "אֱלֹהִ֖ים  Deities\n",
      "בָּרָ֣א  Exist\n",
      "אֹתֹ֑ו  Identifiers\n",
      "זָכָ֥ר  Sex\n",
      "נְקֵבָ֖ה  Sex\n",
      "בָּרָ֥א  Exist\n",
      "אֹתָֽם׃  Identifiers\n",
      "יְבָ֣רֶךְ  Bless\n",
      "אֹתָם֮  Identifiers\n",
      "אֱלֹהִים֒  Deities\n",
      "יֹּ֨אמֶר  Speak\n",
      "אֱלֹהִ֗ים  Deities\n",
      "פְּר֥וּ  Quantity\n",
      "רְב֛וּ  Quantity|Frequency\n",
      "מִלְא֥וּ  Contain\n",
      "אֶת־ Identifiers\n",
      "אָ֖רֶץ  Land\n",
      "כִבְשֻׁ֑הָ  Control\n",
      "רְד֞וּ  Control\n",
      "דְגַ֤ת  Aquatic Animals\n",
      "יָּם֙  Waterbodies\n",
      "עֹ֣וף  Birds\n",
      "שָּׁמַ֔יִם  Universe\n",
      "כָל־ Complete\n",
      "חַיָּ֖ה  Alive|Animals\n",
      "רֹמֶ֥שֶׂת  Move\n",
      "עַל־ Location\n",
      "אָֽרֶץ׃  Land\n",
      "יֹּ֣אמֶר  Speak\n",
      "אֱלֹהִ֗ים  Deities\n",
      "הִנֵּה֩  Identifiers\n",
      "נָתַ֨תִּי  Possess\n",
      "אֶת־ Identifiers\n",
      "כָּל־ Complete\n",
      "עֵ֣שֶׂב׀  Crops\n",
      "זֹרֵ֣עַ  Plant|Exist\n",
      "זֶ֗רַע  Plants\n",
      "אֲשֶׁר֙  Description\n",
      "עַל־ Location\n",
      "כָל־ Complete\n",
      "אָ֔רֶץ  Land\n",
      "אֶת־ Identifiers\n",
      "כָּל־ Complete\n",
      "עֵ֛ץ  Trees\n",
      "אֲשֶׁר־ Description\n",
      "בֹּ֥ו  Location\n",
      "פְרִי־ Fruits\n",
      "עֵ֖ץ  Trees\n",
      "זֹרֵ֣עַ  Plant|Exist\n",
      "זָ֑רַע  Plants\n",
      "יִֽהְיֶ֖ה  Identifiers\n",
      "אָכְלָֽה׃  Food\n",
      "כָל־ Complete\n",
      "חַיַּ֣ת  Alive|Animals\n",
      "אָרֶץ  Land\n",
      "כָל־ Complete\n",
      "עֹ֨וף  Birds\n",
      "שָּׁמַ֜יִם  Universe\n",
      "כֹ֣ל׀  Complete\n",
      "רֹומֵ֣שׂ  Move\n",
      "עַל־ Location\n",
      "אָ֗רֶץ  Land\n",
      "אֲשֶׁר־ Description\n",
      "בֹּו֙  Location\n",
      "חַיָּ֔ה  Alive\n",
      "אֶת־ Identifiers\n",
      "כָּל־ Complete\n",
      "יֶ֥רֶק  Color\n",
      "עֵ֖שֶׂב  Crops\n",
      "אָכְלָ֑ה  Food\n",
      "יְהִי־ Happen\n",
      "כֵֽן׃  Referents\n",
      "יַּ֤רְא  See\n",
      "אֱלֹהִים֙  Deities\n",
      "אֶת־ Identifiers\n",
      "כָּל־ Complete\n",
      "אֲשֶׁ֣ר  Description\n",
      "עָשָׂ֔ה  Exist\n",
      "הִנֵּה־ Identifiers\n",
      "טֹ֖וב  Good\n",
      "יְהִי־ Happen\n",
      "עֶ֥רֶב  Time\n",
      "יְהִי־ Happen\n",
      "בֹ֖קֶר  Time\n",
      "יֹ֥ום  Time\n",
      "שִּׁשִּֽׁי׃ פ  Quantity|Frequency\n"
     ]
    }
   ],
   "source": [
    "for w in L.d(T.nodeFromSection(('Genesis', 1)), 'word'):\n",
    "    \n",
    "    if not F.sem_domain.v(w):\n",
    "        continue\n",
    "    \n",
    "    print(T.text([w]), F.sem_domain.v(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15623"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find uncovered nouns\n",
    "\n",
    "uncovereds = []\n",
    "covereds = []\n",
    "\n",
    "for word in F.otype.s('word'):\n",
    "    \n",
    "    if F.pdp.v(word) in {'nmpr', 'subs'}:\n",
    "        \n",
    "        if not F.sem_domain.v(word):\n",
    "            uncovereds.append(word)\n",
    "            \n",
    "        else:\n",
    "            covereds.append(word)\n",
    "            \n",
    "len(uncovereds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1378"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncovered_lexs = collections.Counter(F.lex.v(w) for w in uncovereds)\n",
    "covered_lexs = collections.Counter(F.lex.v(w) for w in covereds)\n",
    "\n",
    "len(uncovered_lexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PNH/', 2127),\n",
       " ('>JC/', 1332),\n",
       " ('CNH/', 643),\n",
       " ('NPC/', 621),\n",
       " ('<JN/', 567),\n",
       " ('JD/', 414),\n",
       " ('<FRJM/', 315),\n",
       " ('<T/', 296),\n",
       " ('<Y/', 288),\n",
       " ('LB/', 268)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncovered_lexs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JHWH/', 6626),\n",
       " ('KL/', 5276),\n",
       " ('BN/', 4932),\n",
       " ('>LHJM/', 2599),\n",
       " ('MLK/', 2521),\n",
       " ('JFR>L/', 2499),\n",
       " ('>RY/', 2459),\n",
       " ('JWM/', 2233),\n",
       " ('BJT/', 2058),\n",
       " ('<M/', 1614)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covered_lexs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Genesis', 9, 5) 4117\n"
     ]
    }
   ],
   "source": [
    "# find examples of unmatched nouns\n",
    "\n",
    "for w in F.otype.s('word'):\n",
    "    \n",
    "    if F.lex.v(w) != 'JD/':\n",
    "        continue\n",
    "    \n",
    "    if not F.sem_domain.v(w):\n",
    "        \n",
    "        print(T.sectionFromNode(w), w)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 4109 W\n",
      "4 4110 >K\n",
      "6 4111 >T\n",
      "8 4112 DM/\n",
      "10 4113 L\n",
      "12 4114 NPC/\n",
      "14 4115 DRC[\n",
      "16 4116 MN\n",
      "18 4117 JD/\n",
      "20 4118 KL/\n",
      "22 4119 XJH/\n",
      "24 4120 DRC[\n",
      "26 4121 W\n",
      "28 4122 MN\n",
      "30 4123 JD/\n",
      "32 4124 H\n",
      "34 4125 >DM/\n",
      "36 4126 MN\n",
      "38 4127 JD/\n",
      "40 4128 >JC/\n",
      "42 4129 >X/\n",
      "44 4130 DRC[\n",
      "46 4131 >T\n",
      "48 4132 NPC/\n",
      "50 4133 H\n",
      "52 4134 >DM/\n"
     ]
    }
   ],
   "source": [
    "# print verse with numbered words for forming a reference tag\n",
    "\n",
    "for i, w in enumerate(L.d(T.nodeFromSection(('Genesis', 9, 5)), 'word')):\n",
    "    \n",
    "    print((i+1)*2, w, F.lex.v(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#00100900500038"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
