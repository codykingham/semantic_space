{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Semantic Space Construction\n",
    "\n",
    "In this NB, I will apply the new `heads` edge feature to extract head nouns from their phrase and record their co-occurring verbs, subjects, objects, and coordinates. Each of these relationships is assigned a weight. Those co-occurrences are then placed into a matrix. Then I assign an associational measure to the counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 3.2.2\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "116 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.01s B book                 from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.01s B chapter              from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.01s B verse                from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.10s B function             from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.19s B lex                  from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.16s B vs                   from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.13s B language             from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.13s B pdp                  from /Users/cody/github/etcbc/bhsa/tf/c\n",
      "   |     0.06s B heads                from /Users/cody/github/semantics/tf/c\n",
      "   |     0.00s Feature overview: 109 for nodes; 6 for edges; 1 configs; 7 computed\n",
      "  7.84s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tf.fabric import Fabric\n",
    "\n",
    "TF = Fabric(locations='~/github', modules=['etcbc/bhsa/tf/c', 'semantics/tf/c'])\n",
    "api = TF.load('''\n",
    "                book chapter verse\n",
    "                function lex vs language\n",
    "                pdp\n",
    "                heads\n",
    "              ''')\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather and Count Noun Relations\n",
    "\n",
    "Now I will gather nouns from the Hebrew Bible and count syntactic co-occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure weights\n",
    "path_weights = {'Subj': {'Pred': 1,\n",
    "                         'Objc': .5\n",
    "                        },\n",
    "                'Objc': {\n",
    "                         'Pred': 1,\n",
    "                         'Subj': .5\n",
    "                        },\n",
    "                'coor': 1\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3023 nouns\n",
      "3847 cooccurrences\n"
     ]
    }
   ],
   "source": [
    "cooccurrences = collections.defaultdict(lambda: collections.Counter()) # noun counts here\n",
    "\n",
    "# Subj/Objc Counts\n",
    "for phrase in F.otype.s('phrase'):\n",
    "    \n",
    "    # skip non-Hebrew sections\n",
    "    language = F.language.v(L.d(phrase, 'word')[0]) \n",
    "    if language != 'Hebrew':\n",
    "        continue\n",
    "    \n",
    "    # skip non subject/object phrases\n",
    "    function = F.function.v(phrase)\n",
    "    if function not in {'Subj', 'Objc'}:\n",
    "        continue\n",
    "        \n",
    "    # get head nouns\n",
    "    nouns = set(F.lex.v(w) for w in E.heads.f(phrase)) # count lexemes only once\n",
    "    if not nouns:\n",
    "        continue\n",
    "        \n",
    "    # gather contextual data\n",
    "    clause = L.u(phrase, 'clause')[0]\n",
    "    good_paths = path_weights[function]\n",
    "    paths = [phrase for phrase in L.d(clause, 'phrase')\n",
    "                if F.function.v(phrase) in good_paths.keys()\n",
    "            ]\n",
    "    \n",
    "    # make the counts\n",
    "    for path in paths:\n",
    "        \n",
    "        pfunct = F.function.v(path)\n",
    "        weight = good_paths[pfunct]\n",
    "        \n",
    "        # count for verb\n",
    "        if pfunct == 'Pred':\n",
    "            verb = [w for w in L.d(path, 'word') if F.pdp.v(w) == 'verb'][0]\n",
    "            verb_lex = F.lex.v(verb)\n",
    "            verb_stem = F.vs.v(verb)\n",
    "            verb_basis = verb_lex + '.' + verb_stem\n",
    "            for noun in nouns:\n",
    "                cooccurrences[noun][verb_basis] += 1\n",
    "            \n",
    "        # count for subj/obj\n",
    "        else:\n",
    "            conouns = E.heads.f(path)\n",
    "            cnoun_bases = set(F.lex.v(w) for w in conouns)\n",
    "            counts = dict((basis, weight) for basis in cnoun_bases)\n",
    "            for noun in nouns:\n",
    "                cooccurrences[noun].update(counts)\n",
    "                \n",
    "    # count coordinates\n",
    "    for noun in nouns:\n",
    "        for cnoun in nouns:\n",
    "            if cnoun != noun:\n",
    "                cooccurrences[noun][cnoun] += path_weights['coor']\n",
    "            \n",
    "cooccurrences = pd.DataFrame(cooccurrences).fillna(0)                \n",
    "                \n",
    "print(len(cooccurrences.columns), 'nouns')\n",
    "print(len(cooccurrences.index), 'cooccurrences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Association Measure\n",
    "\n",
    "log-likelihood ratio G2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
